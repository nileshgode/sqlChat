from langchain_ollama.chat_models import ChatOllama

# Point to the local Ollama model
llm = ChatOllama(model="llama3.1")


